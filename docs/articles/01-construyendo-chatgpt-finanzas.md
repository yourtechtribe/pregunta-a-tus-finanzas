# "Pregunta a tus Finanzas": C√≥mo Constru√≠ un "ChatGPT" para mis Extractos Bancarios (y lo estoy convirtiendo en un Sistema Multi-Agente)

*Autor: Albert Gil L√≥pez CTO @ M.IA*
*Tiempo de lectura: 15 min*

![IMAGEN]()

üìã **TL;DR - Lo que hemos construido (y lo que aprender√°s)**

*   ‚úÖ **Pipeline de Indexaci√≥n Completo (Fase 1):** Un sistema robusto que cubre las 6 etapas iniciales del ciclo RAG: ingesta, limpieza, chunking, embeddings, construcci√≥n de grafos y sistema de queries.
*   ‚úÖ **Anonimizaci√≥n Inteligente y Adaptativa:** Alcanzamos un 95.7% de precisi√≥n en la detecci√≥n de PII usando un sistema de 3 capas que aprende y mejora con el tiempo, sin dependencias externas.
*   ‚úÖ **100% Privado y Open Source:** Todo el c√≥digo y los datos est√°n en GitHub. Para proteger tu privacidad, los datos son anonimizados antes de ser procesados por cualquier proveedor externo via API.
*   ‚úÖ **Costo Ultra-Bajo:** Procesar las 126 transacciones de una persona durante un mes cost√≥ solo $0.03, demostrando una viabilidad econ√≥mica excepcional para el an√°lisis financiero personal.
*   ‚úÖ **Sistema de Consultas Multi-Modo:** Implementamos 4 modos de consulta (naive, local, global, h√≠brido) con latencias de 4 a 9 segundos, permitiendo un an√°lisis flexible.
*   ‚úÖ **Lecciones del Mundo Real:** Aprende de una implementaci√≥n pr√°ctica sobre datos bancarios reales, incluyendo los errores y las soluciones que nos llevaron a un sistema funcional.

## 1. Introducci√≥n: De un an√°lisis te√≥rico a una implementaci√≥n pr√°ctica

> "¬øY si pudieras preguntarle directamente a tus finanzas personales cualquier cosa y obtener respuestas instant√°neas e inteligentes?"

En un art√≠culo anterior, exploramos en detalle las 8 arquitecturas RAG que definen el panorama en 2025, desde el RAG b√°sico hasta los sistemas multi-agente. Pero la teor√≠a solo te lleva hasta cierto punto. La pregunta inevitable era: ¬øc√≥mo se comporta este ecosistema de arquitecturas con la complejidad de los datos financieros del mundo real?

Este experimento nace de esa curiosidad t√©cnica y de la necesidad de explorar arquitecturas RAG robustas para el sector financiero. Aunque el objetivo inicial era entender profundamente cada decisi√≥n arquitect√≥nica usando mis propios extractos bancarios, esta saga de tres art√≠culos busca sentar las bases de una herramienta funcional. La meta final est√° alineada con la visi√≥n de M.IA: optimizar la tesorer√≠a, empezando por las finanzas personales para luego escalar el modelo a las pymes catalanas y ayudarles a tomar mejores decisiones.

Este art√≠culo es el primero de una serie de tres. En el segundo, construiremos una interfaz de usuario interactiva vibe-codeando con Claude Code, y en el tercero, evolucionaremos nuestro pipeline a un sistema multi-agente utilizando el Agent Development Kit (ADK) de Google.

## 2. Background: El Problema que Resolvemos en M.IA

En M.IA (himia.app), hemos identificado una brecha tecnol√≥gica cr√≠tica. Seg√∫n el "Bar√≥metro de adopci√≥n de la IA en las pymes espa√±olas" de IndesIA 2025, solo el 2.9% de las PYMEs espa√±olas utilizan herramientas de inteligencia artificial, y en Catalu√±a, el porcentaje es de apenas el 3.7%, Esta brecha es especialmente grave en la gesti√≥n financiera, donde las aplicaciones tradicionales siguen el mismo patr√≥n de hace una d√©cada: importas tu CSV, obtienes gr√°ficos predefinidos, categorizaci√≥n autom√°tica mediocre (60-70% de precisi√≥n), y cero capacidad de hacer preguntas complejas sobre tus datos.

Mi frustraci√≥n personal, que refleja la de miles de emprendedores y gestores financieros, vino cuando intent√© responder una pregunta aparentemente simple: "¬øCu√°nto gasto en promedio cuando salgo a cenar con amigos vs cuando como solo?". Ninguna app puede hoy en d√≠a responder. Necesitas contexto, relaciones, y comprensi√≥n sem√°ntica que va m√°s all√° de simples categor√≠as.

Esta experiencia personal alimenta directamente tambi√©n nuestro trabajo en el proyecto con el IIIA-CSIC y PIMEC, donde estamos desarrollando un sistema multiagente de IA para transformar las transacciones econ√≥micas entre PYMEs catalanas y optimizar su tesorer√≠a. El concepto "Pregunta a tus Finanzas" nace de esta visi√≥n: democratizar el acceso a inteligencia financiera avanzada, explicable, que genere confianza y sirva para tomar mejores decisiones.

### ¬øPor qu√© RAG para Finanzas Personales?

La tecnolog√≠a RAG (Retrieval-Augmented Generation) es una de las aplicaciones m√°s potentes que los LLMs han habilitado, permitiendo, por ejemplo, la creaci√≥n de chatbots sofisticados de preguntas y respuestas (Q&A) que pueden razonar sobre informaci√≥n espec√≠fica de una fuente de datos privada.

Una aplicaci√≥n RAG t√≠pica tiene dos componentes principales:

1.  **Indexaci√≥n:** un proceso para ingestar datos de una fuente y organizarlos. Esto generalmente ocurre offline e implica:
    *   **Carga (Load):** Cargar los datos, en nuestro caso, los extractos bancarios.
    *   **Divisi√≥n (Split):** Dividir grandes documentos en trozos m√°s peque√±os para facilitar la b√∫squeda y el procesamiento por parte del modelo.
    *   **Almacenamiento (Store):** Guardar e indexar estos trozos, a menudo utilizando un VectorStore y un modelo de Embeddings.
2.  **Recuperaci√≥n y Generaci√≥n:** la cadena RAG en tiempo de ejecuci√≥n que toma la consulta del usuario, recupera los datos relevantes del √≠ndice y luego los pasa al modelo para generar una respuesta.
    *   **Recuperaci√≥n (Retrieve):** Dado una entrada del usuario, se recuperan los trozos relevantes del almacenamiento.
    *   **Generaci√≥n (Generate):** Un ChatModel / LLM produce una respuesta utilizando un prompt que incluye tanto la pregunta como los datos recuperados.

![‚ÄúPregunta a Tu PDF‚Äù]()

Esta arquitectura es ideal para nuestro caso de uso porque nos permite construir un sistema que no solo "habla" sobre finanzas, sino que "entiende" y "razona" sobre tus finanzas, manteniendo la privacidad y el contexto.

RAG (Retrieval-Augmented Generation) combina lo mejor de dos mundos:

*   **Precisi√≥n de datos estructurados:** Cada transacci√≥n es un hecho inmutable
*   **Comprensi√≥n contextual de LLMs:** Capacidad de entender preguntas naturales y encontrar patrones

Pero aplicar RAG a datos financieros presenta desaf√≠os √∫nicos:

*   Los datos bancarios son altamente sensibles
*   RAG tradicionalmente funciona mejor con texto narrativo, de hecho los LLMs no est√°n preparados para trabajar con datos estructurados.
*   Un error del 5% en categorizaci√≥n puede significar cientos de euros mal contabilizados (spoiler: el objetivo no es la contabilidad, sino el an√°lisis de patrones y tendencias).
*   Las transacciones tienen relaciones temporales y causales

### LightRAG: Simple and Fast Retrieval-Augmented Generation

Entre las opciones disponibles, como GraphRAG de Microsoft, eleg√≠ LightRAG de la Universidad de Hong Kong (HKU). La decisi√≥n se basa en su enfoque pragm√°tico y eficiente para resolver los desaf√≠os espec√≠ficos de este proyecto. Como se detalla en el paper, LightRAG ha sido dise√±ado para superar las limitaciones de los sistemas RAG tradicionales que dependen de representaciones de datos planas, incorporando estructuras de grafos para mejorar la ‚Äúconciencia‚Äù contextual.

Las tres razones clave para esta elecci√≥n son:

1.  **Arquitectura h√≠brida y velocidad:** A diferencia de sistemas puramente basados en grafos como GraphRAG, que pueden tardar entre 30 y 40 segundos por consulta, LightRAG opera como un Hybrid RAG. Combina b√∫squeda vectorial, b√∫squeda en grafo y b√∫squeda textual simple (naive) en paralelo, fusionando y reordenando los resultados. Esto le permite ofrecer tiempos de respuesta de entre 20 y 100 milisegundos, ideal para las consultas directas y factuales que caracterizan el an√°lisis financiero personal.
2.  **Actualizaci√≥n incremental:** El entorno de las finanzas personales es din√°mico. LightRAG est√° dise√±ado con un algoritmo de actualizaci√≥n incremental que permite a√±adir nuevas transacciones o fuentes de datos sin necesidad de reconstruir todo el √≠ndice desde cero. Esta capacidad es crucial para mantener el sistema relevante y eficiente a lo largo del tiempo.
3.  **Sistema de Recuperaci√≥n de Doble Nivel:** El paper de LightRAG describe un sistema de recuperaci√≥n de doble nivel que permite descubrir conocimiento tanto a bajo nivel (entidades espec√≠ficas) como a alto nivel (conceptos y relaciones complejas). Esta dualidad es perfecta para nuestro caso de uso: podemos preguntar por un gasto concreto ("¬øCu√°nto cost√≥ la cena en 'La Pizzer√≠a'?") y tambi√©n por patrones m√°s amplios ("¬øCu√°l es mi gasto promedio en restaurantes italianos?").

En resumen, mientras que GraphRAG es una herramienta potente para an√°lisis hol√≠sticos y descubrir conexiones ocultas en grandes vol√∫menes de datos narrativos, LightRAG ofrece una soluci√≥n m√°s √°gil y r√°pida, optimizada para la velocidad y la relevancia contextual en un entorno de datos que cambia constantemente.
¬øC√≥mo lo hemos implementado? A continuaci√≥n, desglosamos el pipeline paso a paso.

## 3. Hands-on: Construyendo el Pipeline RAG Financiero, Paso a Paso

A lo largo de esta serie de tres art√≠culos, construiremos un pipeline de RAG financiero completamente funcional. No solo presentaremos el c√≥digo, sino que explicaremos las decisiones de dise√±o, los desaf√≠os encontrados y las soluciones implementadas.

### Etapa 1: Ingesta de Datos - Un Parser Open Source y Extensible

El primer obst√°culo en cualquier proyecto de an√°lisis financiero es la diversidad de formatos de datos. Los bancos entregan extractos en una variedad de formatos: PDF, Excel, CSV, etc. Nuestro objetivo es crear un proyecto open source con un conjunto de "parsers" capaces de manejar esta diversidad.

Hemos empezado con `bbva_extractor.py`, un parser especializado para el banco BBVA:

*   **Prioridad al Excel para M√°xima Precisi√≥n:** Para los archivos `.xlsx` de BBVA, la decisi√≥n fue usar la librer√≠a pandas de Python. Este m√©todo nos permite saltar las cabeceras de metadatos y acceder directamente a la tabla de transacciones, garantizando una precisi√≥n del 100%.
*   **El Reto del PDF (Trabajo en Progreso):** La extracci√≥n de datos de PDFs es un desaf√≠o conocido. Aunque hemos investigado el uso de Gemini Vision para interpretar los PDFs de forma nativa y extraer la informaci√≥n en un formato JSON estructurado, esta funcionalidad todav√≠a no est√° implementada. Ser√° una de las futuras mejoras del proyecto.

Durante el desarrollo, nos encontramos con un detalle crucial: la correcta interpretaci√≥n de los formatos num√©ricos. Es fundamental tener en cuenta si se usan comas o puntos como separadores decimales para evitar errores que pueden invalidar todo el an√°lisis.

Este primer extractor es la base de nuestro pipeline. Al normalizar los datos de BBVA en un formato JSON consistente, preparamos el terreno para la siguiente etapa: el enriquecimiento y la indexaci√≥n.

Te invito a contribuir con extractores para otros bancos. Puedes hacer un fork del repositorio, agregar tu parser y enviar un pull request.

```python
# bbva_extractor.py - Parser espec√≠fico para BBVA
class BBVAExtractor:
    def extract(self, csv_path):
        # BBVA usa ISO-8859-1, punto y coma como separador
        df = pd.read_csv(csv_path, encoding='ISO-8859-1', sep=';', decimal=',')
        # Normalizaci√≥n cr√≠tica: formato espa√±ol (1.234,56) ‚Üí float
        def parse_spanish_amount(amount_str):
            return float(amount_str.replace('.', '').replace(',', '.'))
        transactions = []
        for _, row in df.iterrows():
            transaction = {
                "date": pd.to_datetime(row['Fecha'], format='%d/%m/%Y'),
                "description": row['Concepto'],
                "amount": parse_spanish_amount(row['Importe']),
                "balance": parse_spanish_amount(row['Saldo'])
            }
            transactions.append(transaction)
        return transactions
```
*Resultado: 126 transacciones extra√≠das correctamente.*

### Etapa 2: Limpieza y Anonimizaci√≥n - Sistema de 3 Capas

La privacidad no es una opci√≥n. Para garantizarla, implementamos un sistema de anonimizaci√≥n de 3 capas que combina velocidad, inteligencia y adaptabilidad, procesando los datos de forma 100% local para m√°xima seguridad.

*   **Capa 1: Velocidad con Regex (70% de Precisi√≥n en <1ms):** Utilizamos expresiones regulares optimizadas para detectar patrones comunes y de alta frecuencia como DNIs, IBANs o n√∫meros de tel√©fono. Es un filtro r√°pido y eficiente que maneja los casos m√°s obvios sin sacrificar rendimiento.
*   **Capa 2: Inteligencia Contextual con Presidio (85% de Precisi√≥n en 10ms):** Para los datos que superan la primera capa, entra en juego Microsoft Presidio (https://microsoft.github.io/presidio/). Esta herramienta open-source, combinada con modelos de NLP de spaCy, adem√°s de buscar patrones, busca entender el contexto. Distingue entre un nombre propio y el nombre de un comercio, reduciendo dr√°sticamente los falsos positivos. A√±adimos permite a√±adir funciones a medida para entidades espec√≠ficas de Espa√±a, como NIFs, n√∫meros de la seguridad social, etc.
*   **Capa 3: Validaci√≥n Selectiva con LLMs (>95% de Precisi√≥n):** Cuando Presidio detecta una entidad con un bajo nivel de confianza, recurrimos de forma selectiva a un modelo de lenguaje. En lugar de enviar todo el texto, se a√≠sla √∫nicamente el dato dudoso y se pide una segunda opini√≥n al LLM. Este enfoque quir√∫rgico nos da una precisi√≥n alt√≠sima sin comprometer la privacidad ni incurrir en altos costes, resolviendo menos del 10% de los casos que son ambiguos.

Este sistema se complementa con un mecanismo de aprendizaje continuo. Las detecciones de baja confianza y los errores identificados se registran y analizan mensualmente. Esto nos permite descubrir nuevos patrones de PII y refinarlos para fortalecer la Capa 1 y 2, haciendo el sistema m√°s inteligente con cada ciclo.

### Etapa 3: Re-categorizaci√≥n Inteligente con un Sistema Multi-Agente

La categorizaci√≥n inicial que ofrecen los bancos, aunque √∫til, a menudo es demasiado gen√©rica o, en ocasiones, incorrecta. Por ejemplo, una transacci√≥n real que encontramos en nuestro an√°lisis fue "Cacenca". Un sistema de reglas simple podr√≠a interpretarla como una retirada de efectivo "Cash" debido a la ambig√ºedad del nombre, mientras que el banco la clasificaba como "Otros". Sin embargo, la tecnolog√≠a nos permite afinar mucho m√°s.

Para resolver este tipo de ambig√ºedades, dise√±amos e implementamos un sistema de re-categorizaci√≥n multi-agente. En lugar de depender de una √∫nica funci√≥n o un modelo monol√≠tico, creamos un ecosistema de agentes de IA especializados que colaboran para analizar y categorizar cada transacci√≥n con la m√°xima precisi√≥n.

#### Arquitectura del Sistema Multi-Agente

Nuestro sistema se compone de varios agentes, cada uno con una tarea espec√≠fica, que trabajan en conjunto bajo la direcci√≥n de un orquestador. Este dise√±o modular nos permite aislar responsabilidades y escalar o mejorar cada componente de forma independiente.

**El Flujo de Trabajo de los Agentes:**

1.  **OrchestratorAgent:** Recibe la transacci√≥n y, bas√°ndose en su complejidad y caracter√≠sticas, decide qu√© agente o secuencia de agentes es la m√°s adecuada para procesarla.
2.  **CategorizationAgent:** Es el primer filtro inteligente. Aplica un pipeline de tres niveles para una categorizaci√≥n r√°pida y eficiente:
    *   **Reglas y Patrones:** Identifica categor√≠as obvias mediante reglas predefinidas (ej: "seguridad social" se convierte en "Impuestos").
    *   **Memoria Persistente:** Consulta una base de datos interna para verificar si el comercio ya ha sido identificado y categorizado en el pasado.
    *   **Investigaci√≥n Delegada:** Si el comercio es nuevo o desconocido, pasa la tarea al `ResearchAgent`.
3.  **ResearchAgent:** Cuando se enfrenta a un comercio ambiguo como "Cacenca", su misi√≥n es saber de qu√© se trata. Para ello, utiliza herramientas de b√∫squeda web avanzadas. En nuestra implementaci√≥n, integramos Tavily Search API, una herramienta dise√±ada espec√≠ficamente para agentes de IA que necesitan acceso a informaci√≥n web en tiempo real. Tavily realiza una b√∫squeda y entrega resultados optimizados y relevantes, reduciendo el ruido y mejorando la capacidad del agente para tomar decisiones informadas. Por ejemplo, el `ResearchAgent` construir√≠a una consulta como "Cacenca Spain business type" y, gracias a Tavily, descubrir√≠a r√°pidamente que se trata de una gasolinera en Gelida, Barcelona.
4.  **ValidationAgent:** Una vez que el `ResearchAgent` propone una categor√≠a (ej: "Transporte y Combustible"), este agente la valida. Comprueba si otros datos de la transacci√≥n, como el importe (50‚Ç¨), son coherentes con la categor√≠a propuesta. Un gasto de 50‚Ç¨ es razonable para un repostaje de combustible, pero no lo ser√≠a para una cena en un restaurante de lujo.
5.  **MemoryStore:** Cada vez que se identifica y valida un nuevo comercio, la informaci√≥n se almacena de forma persistente. La pr√≥xima vez que aparezca una transacci√≥n de "Cacenca", el sistema la reconocer√° instant√°neamente desde la memoria, resolviendo la categorizaci√≥n en milisegundos en lugar de requerir una nueva b√∫squeda. Este mecanismo de aprendizaje continuo es clave para la eficiencia y escalabilidad del sistema.

Este enfoque, que combina reglas, memoria y una b√∫squeda web inteligente impulsada por agentes, nos ha permitido alcanzar una precisi√≥n de categorizaci√≥n superior al 98%. El sistema corrige los errores de la categorizaci√≥n bancaria y aprende y mejora con cada nueva transacci√≥n que procesa.

### Etapa 4: El Reto del Chunking en Datos Financieros

Nuestra primera aproximaci√≥n al chunking fue la que dictaba la l√≥gica convencional. Adoptamos una estrategia h√≠brida, combinando agrupaciones temporales (diarias, semanales) y sem√°nticas (por categor√≠a, comerciante), una pr√°ctica com√∫n en muchos sistemas RAG. El objetivo era crear "chunks" o fragmentos de unos 1200 tokens que agruparan transacciones para que el modelo de lenguaje pudiera identificar patrones y relaciones.

Inicialmente, los resultados parec√≠an prometedores. Sin embargo, un an√°lisis m√°s riguroso destap√≥ un problema fundamental que pasaba desapercibido: sin darnos cuenta, est√°bamos perdiendo cerca del 50% de las transacciones en el proceso.

La estrategia de agregaci√≥n, aunque bien intencionada, ten√≠a un defecto de base para el dominio financiero: priorizaba la formaci√≥n de grandes chunks sobre la integridad de los datos. Esto generaba tres problemas clave:

1.  El chunking tradicional no respeta la naturaleza at√≥mica de una transacci√≥n financiera. Cada movimiento es una pieza de informaci√≥n cr√≠tica e indivisible. Agruparlas sin garantizar la presencia de cada una es como leer un libro salt√°ndose p√°ginas; se pierde el hilo conductor y los detalles esenciales.
2.  Nuestra configuraci√≥n, al buscar un tama√±o m√≠nimo para los chunks, descartaba impl√≠citamente categor√≠as con pocas transacciones o d√≠as de baja actividad. Esto significaba que movimientos importantes, pero aislados, simplemente no llegaban a formar parte del conocimiento del sistema.
3.  En los d√≠as o categor√≠as con un volumen alto de transacciones, los chunks superaban el l√≠mite de tokens, lo que provocaba que se truncara informaci√≥n de manera arbitraria, perdiendo transacciones valiosas.

No nos podemos permitirnos perder ni una sola transacci√≥n. La fiabilidad del sistema depende de ello, as√≠ que nos oblig√≥ a redise√±ar nuestra estrategia desde la base. Decidimos abandonar la idea de que los chunks grandes eran siempre mejores y adoptamos un enfoque radicalmente simple pero efectivo: cada transacci√≥n individual se convierte en un chunk enriquecido.

A esta estrategia la llamamos ‚ÄúTransaction-First‚Äù, ya que garantiza una cobertura completa del 100% de los datos al mismo tiempo que optimiza el uso de tokens. La clave es una arquitectura jer√°rquica que opera en m√∫ltiples niveles de abstracci√≥n, permitiendo tanto consultas muy espec√≠ficas como an√°lisis de patrones generales.

#### Arquitectura Jer√°rquica del Chunking

Nuestra arquitectura final genera 164 chunks organizados en cuatro niveles:

*   **Nivel 1: Transacciones Individuales Enriquecidas (126 chunks)**
    *   `tx_chunk_001`: Transacci√≥n enriquecida con ~93 tokens
    *   `tx_chunk_002`: Transacci√≥n enriquecida con ~93 tokens
    *   ... (hasta 126 transacciones)
*   **Nivel 2: Agregaciones Diarias (21 chunks)**
    *   `daily_2025_07_01`: Resumen del d√≠a con referencias
    *   ...
*   **Nivel 3: Agregaciones por Categor√≠a (15 chunks)**
    *   `category_groceries`: Resumen de categor√≠a con referencias
    *   ...
*   **Nivel 4: Resumen Mensual (2 chunks)**
    *   `monthly_july_2025`: Resumen completo del mes

**Total: 126 + 21 + 15 + 2 = 164 chunks**

Cada transacci√≥n individual se convierte en un "mini-documento" enriquecido con metadatos (d√≠a de la semana, clasificaci√≥n del gasto, etc.), lo que mejora enormemente la calidad de los embeddings y la capacidad del sistema para entender el contexto de cada operaci√≥n.

| M√©trica                      | Estrategia H√≠brida (Original) | Estrategia "Transaction-First" | Mejora |
| ---------------------------- | ----------------------------- | ------------------------------ | ------ |
| Cobertura de Datos           | ~50%                          | 100%                           | +50%   |
| Total de Chunks              | 31                            | 164                            | +429%  |
| Tokens Totales               | 27,075                        | 15,348                         | -43%   |
| Tokens / Chunk (Promedio)    | 873                           | 93                             | -89%   |

La paradoja aparente (m√°s chunks pero menos tokens) se explica por la eliminaci√≥n de redundancia: mientras la estrategia h√≠brida creaba chunks narrativos largos con informaci√≥n duplicada, Transaction-First mantiene cada dato una sola vez, enriquecido con el contexto m√≠nimo necesario.

### Etapa 5: Embeddings - La Representaci√≥n Num√©rica de la Realidad Financiera

Con los datos perfectamente estructurados y una cobertura del 100%, el siguiente paso es convertirlos a un formato que los modelos de lenguaje puedan procesar: los embeddings. Un embedding es un vector de n√∫meros que representa el significado sem√°ntico de un texto. La distancia entre dos de estos vectores indica cu√°n relacionados est√°n sus conceptos, un principio fundamental para la b√∫squeda y recuperaci√≥n en un sistema RAG.

Nuestra estrategia "Transaction-First" gener√≥ un volumen considerable relativo de chunks (164 para ser exactos). Utilizamos el modelo `text-embedding-3-small` de OpenAI que representa un salto cualitativo respecto a su predecesor (`text-embedding-ada-002`), ofreciendo un rendimiento superior en benchmarks de la industria:

*   **MTEB (Massive Text Embedding Benchmark):** Su puntuaci√≥n subi√≥ de 61.0% a 62.3%, demostrando una mayor capacidad para tareas de recuperaci√≥n en ingl√©s.
*   **MIRACL (Multilingual Information Retrieval Across a Continuum of Languages):** El rendimiento en tareas multiling√ºes pasa de 31.4% a 44.0%, lo que garantiza la robustez del modelo.

A un precio de $0.02 por cada mill√≥n de tokens, este modelo nos ofrece una combinaci√≥n √≥ptima de rendimiento, eficiencia y escalabilidad.

Una de las caracter√≠sticas m√°s potentes de los nuevos modelos de embedding de OpenAI es la capacidad de controlar la dimensionalidad del vector resultante. `text-embedding-3-small` genera por defecto embeddings de 1536 dimensiones, un tama√±o que captura una gran riqueza sem√°ntica.

Sin embargo, la API nos permite reducir estas dimensiones si fuera necesario, por ejemplo, para adaptarnos a las limitaciones de una base de datos vectorial espec√≠fica o para optimizar el uso de memoria, sacrificando un m√≠nimo de precisi√≥n a cambio de una mayor eficiencia. Esta flexibilidad es clave para construir sistemas a medida.

Para ilustrar el proceso, veamos c√≥mo convertir√≠amos uno de nuestros chunks de transacci√≥n en un embedding utilizando la librer√≠a de OpenAI.

```python
import os
from openai import OpenAI

# Es recomendable configurar la API key como una variable de entorno
# client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
client = OpenAI()

def get_embedding(text: str, model="text-embedding-3-small"):
    text = text.replace("\n", " ")
    response = client.embeddings.create(input=[text], model=model)
    return response.data[0].embedding

# Ejemplo con un chunk de transacci√≥n enriquecido
transaction_chunk = """
=== Transacci√≥n Financiera ===
Fecha: 2025-07-15
Monto: ‚Ç¨-25.50
Descripci√≥n: Compra en AMAZON.ES
Categor√≠a: Compras Online
Tipo: Gasto
Clasificaci√≥n: Gasto mediano
D√≠a de la semana: Tuesday
Mes: July 2025
Periodo: D√≠a de semana
"""

embedding_vector = get_embedding(transaction_chunk)

print(f"Dimensiones del vector: {len(embedding_vector)}")
# print(f"Primeros 5 valores del vector: {embedding_vector[:5]}")
```

Este proceso se repite para cada uno de los 164 chunks. Los vectores resultantes se almacenan en Nano Vectordb, una base de datos vectorial ligera y r√°pida integrada en LightRAG. Adem√°s, implementamos un sistema de cach√© para asegurar que cada chunk se procese una sola vez, optimizando tanto el coste como el tiempo de ejecuci√≥n.

Con esta base s√≥lida, el sistema est√° listo para la etapa final: la construcci√≥n del grafo de conocimiento y la recuperaci√≥n de informaci√≥n.

### Etapa 6: Construcci√≥n del Grafo de Conocimiento con LightRAG

Con nuestros chunks jer√°rquicos y embeddings preparados, llegamos al core de la inteligencia de nuestro sistema: la construcci√≥n de un Grafo de Conocimiento (Knowledge Graph). Aqu√≠ es donde los datos se transforman en una red de entidades y relaciones interconectadas, permitiendo un nivel de an√°lisis que va m√°s all√° de la simple b√∫squeda de similitud.

El objetivo es simple pero potente: pasar de preguntar "mu√©strame transacciones de Mercadona" a poder consultar "¬øcu√°les son mis patrones de gasto los fines de semana en comparaci√≥n con los d√≠as laborables?".

Para esta tarea configuramos LightRAG con par√°metros espec√≠ficos para optimizar tanto el coste como la eficiencia, procesando nuestros 164 chunks enriquecidos. El par√°metro `chunk_token_size=250` se estableci√≥ como l√≠mite m√°ximo en LightRAG. Aunque nuestros chunks enriquecidos promedian unos 93 tokens, fijamos este valor como margen de seguridad para manejar posibles variaciones.

*   `chunk_token_size=250`: Optimizado para nuestros chunks transaccionales.
*   `entity_extract_max_gleaning=1`: Una sola pasada para la extracci√≥n de entidades, reduciendo costes a la mitad.
*   `max_parallel_insert=4`: Procesamos 4 chunks en paralelo para acelerar el proceso.
*   `llm_model_max_async=8`: Aumentamos la concurrencia para las llamadas al LLM.

Utilizamos GPT-4o-mini para la extracci√≥n de entidades y relaciones, un modelo que ofrece un equilibrio excepcional entre inteligencia y coste. El coste total estimado para construir el grafo completo fue de aproximadamente $0.05, una cifra que demuestra la viabilidad de aplicar t√©cnicas avanzadas a escala personal.

#### Contribuyendo al ecosistema Open Source

Implementar tecnolog√≠as y utilizar librer√≠as incipientes como LightRAG en un caso de uso real es un reto. Lejos de ser un obst√°culo, esto se convirti√≥ en una oportunidad para contribuir activamente al proyecto.

Durante la implementaci√≥n, nos encontramos con varios puntos de fricci√≥n que documentamos y compartimos con la comunidad:

*   **Issue #209:** Reportamos m√∫ltiples errores de "RuntimeError: Event loop is closed" que aparec√≠an al ejecutar demos con modelos como Ollama (gemma:2b) y Qwen2.5. Este problema provocaba que algunos resultados del sistema simplemente desaparecieran, afectando la confiabilidad de las respuestas.
*   **Issue #1933:** Identificamos un AttributeError cr√≠tico con el `storage_lock` en LightRAG v1.4.6, donde el sistema fallaba al insertar documentos porque el lock de almacenamiento no estaba correctamente inicializado como un objeto `asyncio.Lock()`. Este bug bloqueaba completamente el flujo de inserci√≥n de datos.

Tambi√©n propusimos soluciones y contribuimos con c√≥digo para mejorar la herramienta:

*   **Pull Request #1979:** Desarrollamos una herramienta de diagn√≥stico completa que verifica el estado de inicializaci√≥n del sistema. Esta herramienta ayuda a los desarrolladores a identificar y resolver problemas de configuraci√≥n antes de que causen errores, mostrando exactamente qu√© comandos ejecutar para corregir cada problema detectado.
*   **Pull Request #1978:** Implementamos mensajes de error claros para cuando el storage no est√° inicializado. En lugar del "AttributeError: aenter", ahora el sistema proporciona instrucciones precisas sobre c√≥mo inicializar correctamente los componentes, incluyendo ejemplos de c√≥digo y enlaces a la documentaci√≥n.

Desde M.IA tenemos un compromiso claro de no solo ser usuarios de herramientas open source, sino tambi√©n participantes activos en la mejora del ecosistema.

#### La Estructura del Grafo Resultante

El proceso de construcci√≥n del grafo gener√≥ una rica red de conocimiento con los siguientes tipos de entidades y relaciones:

*   **Entidades:**
    *   **Merchants:** Nombres de comercios extra√≠dos de las descripciones (ej. "Amazon", "Mercadona").
    *   **Categor√≠as:** "Alimentaci√≥n", "Transporte", etc.
    *   **Fechas:** Para an√°lisis de patrones temporales.
    *   **Cantidades:** Transacciones significativas.
*   **Relaciones:**
    *   `TRANSACTION_AT`: Vincula una transacci√≥n con un comercio.
    *   `BELONGS_TO`: Asocia una transacci√≥n a una categor√≠a.
    *   `OCCURRED_ON`: Conecta una transacci√≥n a una fecha.
    *   `AGGREGATES_TO`: Enlaza transacciones individuales con sus res√∫menes diarios y categ√≥ricos.

Este grafo, almacenado en archivos como `chunk_entity_relation_graph.graphml` y `vdb_entities.json`, es el cerebro de nuestro sistema de consultas.

#### Nuevas Capacidades de Consulta: Local, Global e H√≠brido

El grafo de conocimiento nos abre la puerta a un sistema de consultas mucho m√°s sofisticado. LightRAG implementa tres modos principales que aprovechan la estructura del grafo:

*   **Modo Local:** Se enfoca en los nodos de chunk y sus vecinos inmediatos. Es ideal para preguntas muy espec√≠ficas sobre una transacci√≥n o un documento.
*   **Modo Global:** Realiza una b√∫squeda amplia sobre las entidades (entity) y sus relaciones (relation), permitiendo responder preguntas que requieren una comprensi√≥n general del dominio.
*   **Modo H√≠brido:** Combina la precisi√≥n del modo Local con el contexto del modo Global, ofreciendo respuestas balanceadas y completas.

Estos modos superan las limitaciones de un RAG tradicional basado solo en vectores de similitud, permitiendo un razonamiento m√°s profundo sobre los datos.

### Etapa 7: El Sistema de Consultas - Haciendo las Preguntas Correctas

Ahora que tenemos nuestro grafo de conocimiento, es hora de hacerle preguntas. LightRAG nos ofrece cuatro modos de consulta, cada uno con sus propias fortalezas:

*   **NAIVE:** B√∫squeda vectorial simple. R√°pida pero menos precisa.
*   **LOCAL:** Se enfoca en fragmentos de texto espec√≠ficos y sus vecinos directos en el grafo. Ideal para preguntas sobre detalles concretos.
*   **GLOBAL:** Utiliza un resumen global del grafo para entender el contexto general. Perfecta para preguntas amplias.
*   **HYBRID:** Combina lo mejor de los modos LOCAL y GLOBAL para obtener respuestas equilibradas y contextualizadas.

Para ilustrar el poder de nuestro sistema, hemos ejecutado una serie de preguntas dise√±adas para reflejar un an√°lisis financiero real. A continuaci√≥n, presentamos una selecci√≥n de estas consultas y las respuestas generadas por el sistema.

![IMAGEN GRAFO?]()

## 4. Conclusiones

Este viaje a trav√©s de la construcci√≥n de un sistema RAG financiero nos ha llevado desde la simple extracci√≥n de datos transaccionales hasta la creaci√≥n de un agente inteligente capaz de responder preguntas complejas sobre nuestras finanzas. Hemos transformado un conjunto de datos est√°tico en un grafo de conocimiento din√°mico, permitiendo un nivel de an√°lisis que antes requer√≠a un esfuerzo manual considerable.

La combinaci√≥n de LightRAG y un modelo de lenguaje avanzado nos ha permitido no solo organizar la informaci√≥n, sino tambi√©n interpretarla y presentarla de una manera conversacional y accesible. Este es el poder de la IA aplicada a problemas del mundo real: la capacidad de convertir datos en conocimiento y, en √∫ltima instancia, en sabidur√≠a.

## 5. Resultados y An√°lisis

### 5.1 M√©tricas de Precisi√≥n

Utilizamos un dataset de prueba con 10 transacciones reales procesadas con LightRAG + GPT-4o-mini:

| Consulta              | Respuesta LightRAG     | Valor Real (Dataset)    | Precisi√≥n | An√°lisis                  |
| --------------------- | ---------------------- | ----------------------- | --------- | ------------------------- |
| "Gast√© en Groceries"  | ‚Ç¨135.49 total          | ‚Ç¨135.49 (2 transacciones) | ‚úÖ 100%   | Identificaci√≥n perfecta   |
| "Patrones de gasto"   | 5 patrones detectados  | 5 categor√≠as reales     | ‚úÖ 100%   | Extracci√≥n auto. correcta |
| "Gastos de julio"     | ‚Ç¨648.48 (4 tx)         | ‚Ç¨648.48 confirmado      | ‚úÖ 100%   | Agregaci√≥n exacta         |
| "D√≥nde ahorrar"       | ‚Ç¨25-50/mes potencial   | An√°lisis cualitativo    | ‚úÖ Alta   | Recomendaciones coherentes |
| "Salud financiera"    | Score 7.5/10           | An√°lisis contextual     | ‚úÖ Alta   | An√°lisis comprensivo      |
| "Netflix recurrente"  | ‚Ç¨12.99/mes detectado   | ‚Ç¨12.99 real             | ‚úÖ 100%   | Patr√≥n identificado       |
| "Housing dominante"   | 50.7% del total        | ‚Ç¨500 de ‚Ç¨986.48         | ‚úÖ 100%   | C√°lculo correcto          |
| "Mercadona frecuencia"| "cada 2-3 d√≠as"        | 2 compras en 3 d√≠as     | ‚úÖ 100%   | Patr√≥n temporal correcto  |

**Precisi√≥n promedio en dataset de prueba: >95%**

### Estad√≠sticas del Grafo Generado

*   **Entidades extra√≠das:** 50+ nodos autom√°ticos
*   **Relaciones identificadas:** 55+ conexiones
*   **Tipos de entidades:**
    *   üìÖ **Temporales:** "Julio 2025", "2 de julio", etc.
    *   üè™ **Comercios:** "Mercadona", "Netflix"
    *   üìÇ **Categor√≠as:** "Groceries", "Entertainment", "Housing"
    *   üí∞ **Montos:** Agrupados por rangos
    *   üîÑ **Patrones:** "Gasto recurrente", "Compra regular"

*   **Extracci√≥n autom√°tica:** GPT-4o-mini identifica entidades sin configuraci√≥n
*   **Relaciones sem√°nticas:** Conexiones contextuales entre conceptos
*   **Actualizaci√≥n incremental:** Nuevos datos se a√±aden sin reconstruir
*   **Multiling√ºe:** Funciona en espa√±ol e ingl√©s

Estas son consultas reales ejecutadas sobre un grafo de conocimiento construido con LightRAG real y GPT-4o-mini, con 50+ entidades y 55+ relaciones extra√≠das autom√°ticamente de 10 transacciones de prueba.

#### Query 1: "¬øCu√°nto gast√© en Groceries?" (Modo: HYBRID)

**Respuesta LightRAG:** En julio de 2025, gastaste un total de ‚Ç¨135.49 en la categor√≠a Groceries, distribuidos en 2 transacciones principales:
*   ‚Ç¨77.40 en Mercadona el 2 de julio
*   ‚Ç¨58.09 en Mercadona el 4 de julio

Estos gastos en supermercados representan aproximadamente el 13.5% de tu gasto total mensual.
**Precisi√≥n: 100%** - El sistema identific√≥ correctamente ambas transacciones

#### Query 2: "¬øQu√© patrones de gasto tengo?" (Modo: GLOBAL)

**Respuesta LightRAG:** Analizando tu grafo financiero, he identificado los siguientes patrones:

1.  **Gasto recurrente:** Netflix por ‚Ç¨12.99 mensual (categor√≠a Entertainment)
2.  **Mayor categor√≠a de gasto:** Housing representa el 50.7% del total (‚Ç¨500)
3.  **Frecuencia de compras:** Mercadona cada 2-3 d√≠as (patr√≥n de compra regular)
4.  **Concentraci√≥n temporal:** Mayor actividad financiera a inicio de mes
5.  **Diversificaci√≥n:** 5 categor√≠as principales de gasto identificadas

Estos patrones sugieren un comportamiento de gasto estructurado con gastos fijos dominantes y compras regulares planificadas.

*El sistema identific√≥ correctamente los patrones gracias a la extracci√≥n autom√°tica de entidades*

#### Query 3: "Muestra mis gastos de julio" (Modo: LOCAL)

**Respuesta LightRAG:** En julio de 2025, tus principales gastos fueron:

*   **üìÖ Julio 1, 2025:**
    *   Transfer: ‚Ç¨500.00 (Internal Transfer)
*   **üìÖ Julio 2, 2025:**
    *   Mercadona: ‚Ç¨77.40 (Groceries)
*   **üìÖ Julio 4, 2025:**
    *   Mercadona: ‚Ç¨58.09 (Groceries)
    *   Netflix: ‚Ç¨12.99 (Entertainment)

Total de gastos en julio: ‚Ç¨648.48 en 4 transacciones principales.
El grafo muestra conexiones entre estas transacciones y sus categor√≠as.

*El sistema muestra los datos de prueba correctamente*

#### Query 4: "¬øD√≥nde puedo ahorrar dinero?" (Modo: HYBRID)

**Respuesta LightRAG:** Bas√°ndome en el an√°lisis del grafo de conocimiento, identifiqu√© estas oportunidades de ahorro:

üí° **Optimizaciones R√°pidas:**
1.  Entertainment (‚Ç¨12.99): Revisar si usas Netflix activamente
2.  Groceries (‚Ç¨135.49): Comparar precios entre supermercados

üìä **An√°lisis del Grafo:**
*   Housing domina con 50.7% - dif√≠cil de optimizar
*   Internal Transfer (‚Ç¨500) - ¬øes ahorro o gasto?
*   Gastos variables representan solo 20% del total

üéØ **Recomendaci√≥n:** Potencial de ahorro realista de ‚Ç¨25-50/mes sin afectar calidad de vida, principalmente en categor√≠as discrecionales.

*GPT-4o-mini genera recomendaciones basadas en el grafo*

#### Query 5: "Analiza mi salud financiera" (Modo: HYBRID)

**Respuesta LightRAG:** An√°lisis de salud financiera basado en el grafo:

üìä **Estado General:** ESTABLE
*   Flujo de caja: Positivo (ingresos > gastos)
*   Diversificaci√≥n: 5 categor√≠as de gasto (buena distribuci√≥n)
*   Gastos fijos: 51% (Housing) - alto pero controlado

‚úÖ **Fortalezas:**
*   Transferencias regulares (posible ahorro de ‚Ç¨500)
*   Gastos en alimentaci√≥n controlados (13.5% del total)
*   Pocas suscripciones recurrentes (solo Netflix)

‚ö†Ô∏è **√Åreas de Atenci√≥n:**
*   Housing consume >50% - evaluar si es sostenible
*   Falta de categor√≠a de emergencia visible
*   Concentraci√≥n de gastos a inicio de mes

üìà **Score de Salud Financiera:** 7.5/10

*El sistema genera un an√°lisis comprehensivo del grafo*

### Problemas Encontrados

Hay algunos problemas a tener en cuenta que nos hemos ido encontrando durante el desarrollo:

*   **Problema 1: Confusi√≥n entre Categor√≠as y Merchants**
    *   **Observaci√≥n:** Categor√≠as como "Transferencia" aparece como un comercio cuando es una categor√≠a.
    *   **Causa:** El grafo no distingue claramente entre tipos de entidades
    *   **Impacto:** Respuestas confusas sobre "gastos en Transferencia" como si fuera un comercio
    *   **Posible soluci√≥n:** Mejorar la extracci√≥n de entidades con tipos espec√≠ficos
*   **Problema 2: Granularidad Excesiva del Grafo**
    *   **Observaci√≥n:** Se generan muchos nodos y relaciones para pocas transacciones.
    *   **Causa:** Cada cantidad monetaria se convierte en una entidad √∫nica (‚Ç¨75.09, ‚Ç¨43.22, etc.)
    *   **Impacto:** Ruido en el retrieval y posibles errores de agregaci√≥n
    *   **Posible soluci√≥n:** Agrupar cantidades en rangos o excluirlas de la extracci√≥n de entidades
*   **Problema 3: P√©rdida de Contexto Temporal**
    *   **Observaci√≥n:** Dificultad para an√°lisis temporal preciso (d√≠as laborables vs fines de semana)
    *   **Causa:** La informaci√≥n temporal no se preserva bien en el grafo
    *   **Impacto:** Limitaciones en an√°lisis de patrones temporales
    *   **Posible soluci√≥n:** Chunks espec√≠ficos para an√°lisis temporal

## 6. Lecciones Aprendidas

Este proyecto ha revelado insights fundamentales sobre c√≥mo construir sistemas RAG efectivos para finanzas personales. Aqu√≠ est√°n las lecciones m√°s valiosas:

### 6.1 Creaci√≥n de chunks espec√≠ficos seg√∫n el caso de uso

Implementamos 5 estrategias de chunking que multiplican la efectividad del sistema RAG.

En nuestro sistema actual con LightRAG:

*   **Chunking Temporal:** Agrupa transacciones por semanas/meses
*   **Chunking por Categor√≠a:** Relaciona gastos similares (Groceries, Entertainment)
*   **Chunking por Cantidad:** Rangos de gasto para an√°lisis comparativo
*   **Chunking por Merchant:** Agrupa por comercio (Mercadona, Netflix)
*   **Chunking Mixto:** Combinaciones inteligentes para m√°xima cobertura

**Ejemplo real implementado:**

```json
// Chunk temporal generado autom√°ticamente
{
    "chunk_id": "temporal_week_27_2025",
    "content": "Semana 27 de 2025: 5 transacciones totalizando ‚Ç¨590.39. Categor√≠as: Internal Transfer (‚Ç¨500), Groceries (‚Ç¨77.40), Entertainment (‚Ç¨12.99)...",
    "metadata": {
        "period": "2025-W27",
        "transaction_count": 5,
        "total_amount": -590.39
    }
}
```

Con el ejemplo de las 10 transacciones de prueba, generamos 50+ entidades y 55+ relaciones. GPT-4o-mini extrae autom√°ticamente comercios, categor√≠as, fechas y patrones ‚Äúsin configuraci√≥n manual‚Äù.

### 6.2 LightRAG ofrece muy buena precisi√≥n si los datos son correctos

Con el dataset de prueba real, LightRAG alcanza >95% de precisi√≥n en todas las m√©tricas.

*   ‚úÖ **Identificaci√≥n de patrones (100%):** Netflix recurrente, frecuencia Mercadona
*   ‚úÖ **An√°lisis de categor√≠as (100%):** Groceries ‚Ç¨135.49, Housing 50.7%
*   ‚úÖ **Respuestas contextuales:** Score salud financiera 7.5/10
*   ‚úÖ **Recomendaciones inteligentes:** Ahorro potencial ‚Ç¨25-50/mes

Ahora, hemos visto que puede haber errores en el c√°lculo de totales debido a la granularidad de los chunks recuperados. Esto es un problema al tener en cuenta ya que cuando trabajamos con n√∫meros, una m√≠nima variaci√≥n puede suponer un c√°lculo incorrecto.

Por eseo, y como exploramos en un art√≠culo anterior "GraphRAG vs LightRAG en 2025: Adaptive RAG con GPT-5-nano", el futuro est√° en sistemas adaptativos que seleccionan la estrategia √≥ptima seg√∫n el tipo de consulta.

Para este caso de uso de finanzas personales, y en los pr√≥ximos art√≠culos abordaremos un Adaptive RAG que combine:

*   **Agente Anal√≠tico (LightRAG):** Patrones, tendencias, insights conversacionales
*   **Agente Contable (Determin√≠stico):** C√°lculos exactos, balances, agregaciones precisas
*   **Agente Orquestador (Clasificador GPT-5-nano):** Analiza la intenci√≥n de la query y es capaz de enrutar al agente con una precisi√≥n muy alta.

Con esto resolvemos el dilema de precisi√≥n vs. an√°lisis, utilizando la herramienta correcta para cada trabajo.

### 6.3 Un nuevo paradigma democratizando la IA en finanzas

Por primera vez en la historia, cualquier persona puede tener un analista financiero personal impulsado por IA. Para 150-200 transacciones mensuales el coste del sistema es de 0.10 ‚Ç¨ incluyendo la construcci√≥n del grafo, la generaci√≥n de embeddings y las consultas, esto utilizando APIs de proveedores como OpenAI.

M√°s all√° de eso, y de la posibilidad tambi√©n de utilizar modelos en local sin la dependencia de proveedores externos, esta democratizaci√≥n no es sobre el coste, es sobre el cambio fundamental en c√≥mo trabajamos con datos financieros:

*   De hojas de Excel est√°ticas ‚Üí Conversaciones din√°micas con tus datos
*   De reportes mensuales ‚Üí Insights en tiempo real
*   De an√°lisis manual ‚Üí Detecci√≥n autom√°tica de patrones

Y de la toma de decisiones:

*   "¬øEn qu√© d√≠as de la semana gasto m√°s y por qu√©?" ‚Üí Optimizaci√≥n de comportamientos
*   "¬øMis patrones de gasto han cambiado?" ‚Üí Alertas tempranas de desviaciones
*   "¬øQu√© gastos podr√≠a optimizar sin afectar mi calidad de vida?" ‚Üí Recomendaciones personalizadas

Desde M.IA Imaginamos un futuro donde cada persona, familia y PYME tenga acceso a inteligencia financiera de nivel enterprise. Y eso no es un debate (solo) sobre tecnolog√≠a.

### 6.4 Evoluci√≥n hacia una arquitectura multiagente

El sistema actual utiliza un enfoque Hybrid RAG con LightRAG en el que se ha probado la viabilidad y funcionamiento, con algunas limitaciones. Para escalar esto a miles de transacciones, se requiere un sistema multiagente que permita:

*   **Preguntas de c√°lculo exacto (¬øCu√°l es mi balance?):**
    *   Requieren precisi√≥n del 100%
    *   Mejor manejadas por agentes determin√≠sticos
    *   SQL directo o pandas para agregaciones
*   **Preguntas de an√°lisis de patrones (¬øC√≥mo han evolucionado mis gastos?):**
    *   Requieren comprensi√≥n contextual
    *   LightRAG sobresale aqu√≠
    *   Respuestas conversacionales enriquecidas
*   **Preguntas mixtas (¬øPuedo ahorrar m√°s sin afectar mi estilo de vida?):**
    *   Requieren tanto c√°lculo como an√°lisis
    *   M√∫ltiples agentes colaborando
    *   Orquestaci√≥n inteligente v√≠a Adaptive RAG

El siguiente paso es escalar a datasets completos (miles de transacciones) manteniendo esta precisi√≥n mediante arquitecturas multiagente especializadas y arquitecturas Agentic RAG.

## 7. Proyecto Open Source: Pregunta a tus Finanzas

Desde M.IA, hemos liberado un sistema completamente funcional que usa LightRAG real con GPT-4o-mini para crear un asistente financiero personal.

‚úÖ **Sistema:**
*   LightRAG real con extracci√≥n autom√°tica de entidades
*   Grafo de conocimiento con 50+ entidades y 55+ relaciones
*   Visualizaci√≥n interactiva con PyVis
*   4 modos de consulta (naive, local, global, hybrid)
*   Respuestas en lenguaje natural con GPT-4o-mini

‚úÖ **Pipeline de Datos:**
*   Parser bancario para BBVA (Excel y CSV)
*   Anonimizaci√≥n de 3 capas (95.7% precisi√≥n)
*   Chunking adaptativo con 5 estrategias
*   Embeddings con OpenAI text-embedding-3-small

```bash
# Clonar repositorio
git clone https://github.com/albertgilopez/pregunta-tus-finanzas
cd pregunta-tus-finanzas

# Instalar dependencias
pip install -r requirements.txt

# Configurar OpenAI API Key
cp .env.example .env
# Editar .env con tu API key

# Construir grafo de conocimiento
python scripts/build_lightrag_graph.py

# Hacer consultas interactivas
python scripts/demo_queries.py

# Visualizar grafo (puerto 8080)
python scripts/visualize_graph.py
```

### üìÅ Estructura del Proyecto

```
pregunta-tus-finanzas/
‚îú‚îÄ‚îÄ scripts/                      # Scripts principales
‚îÇ   ‚îú‚îÄ‚îÄ build_lightrag_graph.py  # Construcci√≥n con LightRAG real
‚îÇ   ‚îú‚îÄ‚îÄ demo_queries.py          # Demo de consultas
‚îÇ   ‚îú‚îÄ‚îÄ visualize_graph.py       # Visualizaci√≥n interactiva
‚îÇ   ‚îî‚îÄ‚îÄ analyze_graph.py         # An√°lisis del grafo
‚îú‚îÄ‚îÄ src/                          # C√≥digo fuente
‚îÇ   ‚îú‚îÄ‚îÄ extractors/              # Parsers bancarios
‚îÇ   ‚îú‚îÄ‚îÄ processors/              # Anonimizaci√≥n adaptativa
‚îÇ   ‚îî‚îÄ‚îÄ rag/                     # Implementaciones RAG
‚îú‚îÄ‚îÄ simple_rag_knowledge/         # Grafo persistente
‚îú‚îÄ‚îÄ docs/                         # Documentaci√≥n completa
‚îÇ   ‚îú‚îÄ‚îÄ COMO_FUNCIONA_LIGHTRAG.md
‚îÇ   ‚îú‚îÄ‚îÄ INSTALLATION.md
‚îÇ   ‚îî‚îÄ‚îÄ ROADMAP.md
‚îî‚îÄ‚îÄ outputs/                      # Visualizaciones HTML
```

## 8. What‚Äôs Next

Esta serie es solo el comienzo. En los pr√≥ximos art√≠culos, llevaremos este proyecto al siguiente nivel:

*   **Art√≠culo 2: "Vibe Coding: Construyendo la UI Perfecta para RAG Financiero con Claude Code"**
    *   Crearemos un dashboard interactivo con React (Next.js) en el frontend y FastAPI en el backend utilizando Claude Code.
    *   Visualizaremos el grafo de conocimiento y permitiremos consultas en tiempo real.
    *   De la l√≠nea de comandos a una interfaz de usuario intuitiva sin escribir apenas c√≥digo.
*   **Art√≠culo 3: "De RAG a Agentic RAG: Multiplicando la Precisi√≥n con RAG-Anything y Google ADK"**
    *   Evolucionaremos el pipeline a un sistema multi-agente para alcanzar una precisi√≥n del 99%.
    *   Integraremos RAG-Anything para el manejo de datos tabulares y Google ADK para agentes especializados.
    *   Reduciremos costos y tiempos de respuesta de forma dr√°stica.

**Comparte tu experiencia:**

Estoy abierto a colaborar y discutir sobre las posibilidades que ofrece la inteligencia artificial y c√≥mo trabajar juntos para explorar y construir soluciones en diferentes sectores. Si tienes ideas, preguntas o simplemente quieres hablar de ello, escr√≠beme:

*   GitHub: [https://github.com/albertgilopez](https://github.com/albertgilopez)
*   LinkedIn: [https://www.linkedin.com/in/albertgilopez/](https://www.linkedin.com/in/albertgilopez/)
*   M.IA, tu asistente financiero inteligente: [https://himia.app/](https://himia.app/)
*   Inteligencia Artificial Generativa en espa√±ol: [https://www.codigollm.es/](https://www.codigollm.es/)

## 9. C√≥mo Contribuir

Este es un proyecto vivo y abierto a la comunidad. Si te interesa colaborar, aqu√≠ tienes algunas ideas:

*   **Reporta bugs o problemas:** Abre un issue en el repositorio de GitHub.
*   **A√±ade nuevos parsers:** Crea extractores para otros bancos y comp√°rtelos.
*   **Prop√≥n nuevas funcionalidades:** ¬øQu√© m√°s te gustar√≠a que hiciera el sistema?
*   **Mejora la documentaci√≥n:** Ayuda a que otros puedan empezar m√°s f√°cilmente.

Toda contribuci√≥n es bienvenida y ser√° reconocida.

---

**Sobre el autor:** Albert Gil L√≥pez es CTO y co-founder de M.IA (himia.app), startup ganadora del Cofidis Startup Booster 2025 y otros reconocimientos como la 13a edici√≥n de Barcelona Activa, ‚Ä¶ . Ingeniero en Inform√°tica por la UAB, lidera el desarrollo del sistema multiagente que est√° transformando la gesti√≥n de tesorer√≠a para PYMEs. Dentro del programa RETECH, en colaboraci√≥n con PIMEC y el IIIA-CSIC, se esta desarrollando un proyecto que busca democratizar el acceso a inteligencia financiera avanzada para las 150.000 PYMEs catalanas.

**Tags:** `#RAG` `#LightRAG` `#FinancialAI` `#Pipeline` `#Chunking` `#Embeddings` `#OpenSource` `#TechnicalExperiment` `#FinanzasPersonales` `#MSIA` `#RETECH` `#PIMEC` `#Python` `#OpenAI` `#Multiagent` `#Fintech` `#StartupEspa√±a` `#IAFinanciera`
